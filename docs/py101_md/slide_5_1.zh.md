# 第五章 机器学习

在本章中，您将学习到：

*   机器学习的基本概念。
*   机器学习领域中的许多专业术语。
*   关于 `scikit-learn` 模块的几个示例。

## 5.1 机器学习概览

回想一下在柯布-道格拉斯生产函数的例子中，我们希望找到“最优”的 $\alpha$ 值，以便在给定资本和劳动投入的情况下，最准确地估计产出。

!!! note "关键术语"
    *   **模型 (Model):** 描述变量之间关系的方程。例如，$Y = K^\alpha L^{1-\alpha}$ 描述了 $Y$、$K$ 和 $L$ 之间的关系。
    *   **目标变量 (Target variable):** 我们想要预测的变量（位于等式左侧），或者我们想了解其生成机制的变量。在计量经济学中，也称为因变量 (dependent variable) 或响应变量 (response variable)。
    *   **预测变量 (Predictors):** 用于解释或预测目标变量的变量（位于等式右侧）。在计量经济学中，也称为自变量 (independent variable) 或解释变量 (explanatory variable / covariates)。
    *   **参数 (Parameters):** 其值未知的符号。例如，$\alpha$。一旦我们“知道”了参数值，我们就可以计算出模型所对应的目标变量预测值。函数模型和参数代表了我们对数据生成过程（即世界如何运作）的理解。
    *   **估计值 (Estimates):** 由于参数是未知的，我们需要猜测哪个值是最佳的（就像我们寻找 $\alpha$ 时所做的那样）。但即使我们能找到一个最佳值，我们仍然无法确定数据是否真的由该模型生成。这可能是因为我们对世界的理解并不完全正确。在这种情况下，一个错误模型的参数通常是无法被发现的。对于给定的模型，我们能做的最好的就是得到一个估计值。

!!! question "课堂练习 5.1.1：模型、变量与参数识别"
    请识别以下场景中的模型、变量和参数：  
    
    1.  一个研究团队希望预测某些房屋的价格 ($P$)。他们收集了若干房屋的面积 ($A$)、到市中心的距离 ($D$)、房龄 ($G$) 以及建筑材料 ($M$)。他们决定使用一个复杂的关系式：  
        $P = f(l(A,D,G,M))$  
        其中，$l(A,D,G,M) = a + b_1 A + b_2 D + b_3 G + b_4 M$  
        且函数 $f(x)$ 定义为：若 $x \ge 0$，则 $f(x) = x$；否则 $f(x) = 0$。  
    
    2.  另一个团队想了解债券价格 ($R$) 是会上涨还是下跌。他们收集了若干变量，但由于隐私问题，只告诉我们这些变量是 $X_1, X_2, \ldots, X_{15}$。他们的预测方式是（这实际上是一个 Logistic 回归模型的形式）：  
        $Prob(R > 0) = \frac{\exp(l(X_1, X_2, \ldots, X_{15}))}{1 + \exp(l(X_1, X_2, \ldots, X_{15}))}$  
        （这里 $l(X_1, X_2, \ldots, X_{15})$ 代表一个涉及这些变量和一些未知参数的函数，例如线性组合 $\beta_0 + \sum \beta_i X_i$。）

### 分类 (Classification) 与回归 (Regression)

当我们要预测离散化的目标变量时，这个任务称为 **分类 (classification)**。例如：
*   债券价格是上涨还是下跌（而不是具体变动多少）。
*   学生是否能通过一门课程（而不是具体的考试分数）。
*   特朗普是否会提高关税（而不是提高的具体税率）。

当我们要预测一个连续目标变量的具体数值时，这个任务称为 **回归 (regression)**。

### 损失函数 (Loss Function)

**损失函数 (Loss function)** 是告知机器参数估计得有多好的一条规则。例如，我们已经见过绝对误差损失：
$L(\mathbf{y}, \hat{\mathbf{y}}) = \sum_{i} |y_i - \hat{y}_i|$

其他常用的误差包括平方误差损失：
$L(\mathbf{y}, \hat{\mathbf{y}}) = \sum_{i} (y_i - \hat{y}_i)^2$

我们可以通过对损失函数关于参数求导来找到估计值。这个过程也称为“将模型拟合到数据 (fit the model to data)”。

但参数在损失函数中是如何体现的呢？（提示：$\hat{y}_i$ 通常是模型 $f(\mathbf{x}_i; \boldsymbol{\theta})$ 的输出，其中 $\boldsymbol{\theta}$ 是参数）。

机器学习是这样一类方法：它们能够拟合数据，并从某一类函数（具有相同函数形式但参数不同）中帮助找到最佳的数据生成机制（由参数估计值 $\hat{\boldsymbol{\theta}}$ 表示）。
我们要解决的问题可以简化和概括为找到：
$\hat{y}_i = f(\mathbf{x}_i; \hat{\boldsymbol{\theta}})$

在 Python 中，我们希望找到这样一个函数 $f$ 及参数 $\hat{\boldsymbol{\theta}}$。

## 5.2 斜率-截距示例

在第 2.3 章中，我们遇到了一个利用闭包（closure）来固定参数的例子：
```python
def intercept_1():
    a = 1  # 'a' 被内部函数 slope_2 捕获
    def slope_2(x):
        return 2 * x + a # 此处的 a 是外部函数中定义的 a=1
    return slope_2

linear_trans = intercept_1()
print(linear_trans(3)) # 输出应为 2*3 + 1 = 7
```

我们曾练习过修改这个函数，使其更通用，能够接受任意斜率和截距：
```python
def intercept_and_slope(a, b):
    # a (截距) 和 b (斜率) 在这里被 evaluation 函数捕获
    def evaluation(x):
        return a + b * x  # a 和 b 是来自外部作用域 intercept_and_slope 的变量
    return evaluation

# 示例用法:
# line_func = intercept_and_slope(1, 2) # a=1, b=2
# print(line_func(3)) # 输出 1 + 2*3 = 7
```

现在，让我们扩展这个练习来拟合一些数据。假设我们有以下数据点：

| 编号 (No.) | y | x |
| :-------- | :-: | :-: |
| 0         | 0 | 0 |
| 1         | 0 | 1 |
| 2         | 1 | 2 |
| 3         | 3 | 3 |
| 4         | 5 | 4 |

!!! question "课堂练习 5.1.2：拟合数据"
    1.  请使用 Python 的绘图库（如 Matplotlib 或 Seaborn）绘制一个散点图，以观察这组 (x, y) 数据的分布形态。  
    2.  利用我们之前编写的 `intercept_and_slope` 函数的思路，或者定义新的函数，来为模型 $y = a + bx$ 找到最佳的参数 $a$ (截距) 和 $b$ (斜率)。你可以尝试不同的 $a, b$ 值，计算预测值与真实 $y$ 值的某种误差（例如平方误差之和），并试图最小化这个误差。  

## 5.3 两种经典的机器学习方法

您可能已经感受到了，即便是为最简单的机器学习方法（如上述的线性回归），手动编写代码来寻找最优参数估计值也是有一定难度的。对于其他一些机器学习方法，其函数形式要复杂得多，我们有时甚至只能用图示来表示它们！

例如，神经网络模型和分类与回归树模型。

### 示例 5.3.1：神经网络模型

假设我们有5个观测数据和3个解释变量 $x_1, x_2, x_3$。我们要用它们来解释一个连续变量 $y$。一个（非常简化的）神经网络模型可以示意如下：

**输入层 (Input Layer):**
*   $x_1$
*   $x_2$
*   $x_3$

$\Bigg\downarrow$ **线性组合与激活** (通常会有多个神经元，每个神经元执行类似操作)

**隐层神经元 1 (示意):**
1.  **线性计算 ($z_1^{[1]}$):** $x_1, x_2, x_3$ 分别乘以权重 $w_{11}^{[1]}, w_{12}^{[1]}, w_{13}^{[1]}$，加上偏置项 $b_1^{[1]}$。
    $z_1^{[1]} = w_{11}^{[1]}x_1 + w_{12}^{[1]}x_2 + w_{13}^{[1]}x_3 + b_1^{[1]}$
    (原文中的 $a, b_1, b_2, b_3$ 可以理解为这里的偏置和权重)
2.  **激活 ($a_1^{[1]}$):** 将 $z_1^{[1]}$ 通过一个非线性激活函数，如 ReLU。
    $a_1^{[1]} = \text{ReLU}(z_1^{[1]})$
    (原文中的 $c_1^{[1]}$)

($[1]$ 表示第一层，下标 $1$ 表示该层的第一个神经元。)

这只是一个非常简化的单神经元隐层示例。实际的神经网络通常包含多个隐层，每层有多个神经元。

#### 一个更复杂的神经网络片段

现在，让我们展示一个更接近实际、但仍然是片段式的神经网络计算过程。假设输入为 $x_1, x_2, x_3$。

对于隐层（假设是第一层，用 $\langle 1 \rangle$ 表示）的第一个神经元，其激活前的线性计算值为 $\hat{z}_1^{\langle 1 \rangle}$ (原文为 $\෤𝑎1$，这里用 $\hat{z}$ 表示加权和)：
$\hat{z}_1^{\langle 1 \rangle} = b_1^{\langle 1 \rangle} + w_{11}^{\langle 1 \rangle} x_1 + w_{12}^{\langle 1 \rangle} x_2 + w_{13}^{\langle 1 \rangle} x_3$

对于该隐层的第二个神经元，其激活前的线性计算值为 $\hat{z}_2^{\langle 1 \rangle}$ (原文为 $\෤𝑎2$)：
$\hat{z}_2^{\langle 1 \rangle} = b_2^{\langle 1 \rangle} + w_{21}^{\langle 1 \rangle} x_1 + w_{22}^{\langle 1 \rangle} x_2 + w_{23}^{\langle 1 \rangle} x_3$

然后，这些值会经过激活函数得到 $a_1^{\langle 1 \rangle} = g(\hat{z}_1^{\langle 1 \rangle})$ 和 $a_2^{\langle 1 \rangle} = g(\hat{z}_2^{\langle 1 \rangle})$ (原文示意为 $a_1, a_2$)。这些激活后的值 $a_1^{\langle 1 \rangle}, a_2^{\langle 1 \rangle}$ 可以作为下一层的输入，或者如果这是输出层前的最后一层，它们将被用来计算最终的预测值 $\hat{y}$ (原文为 $\ො𝑦$)。

一个可能的简化结构示意图：
```
Inputs: x1, x2, x3
   |
   v
Hidden Layer (e.g., 2 neurons):
  Neuron 1: calculates z1, then a1 = g(z1) ---+
  Neuron 2: calculates z2, then a2 = g(z2) ---|
                                             |
                                             v
Output Layer (combines a1, a2, etc.) ----> y_hat
```

### 示例 5.3.2：决策树模型

让我们回顾一下鸢尾花 (iris) 数据集，其中...
(讲义文本在此处中断)
对于最简单的机器学习方法（例如线性回归），其函数估计式的形式相对简单。然而，对于其他一些机器学习方法，函数形式要复杂得多，有时我们甚至只能用图示来表示它们，例如神经网络模型和分类回归树模型。

## 5.3 两种经典的机器学习方法

### 示例 5.3.1 神经网络模型

假设我们有5个观测样本和3个解释变量（$x_1, x_2, x_3$），我们的目标是解释一个连续变量 $y$。一个简单的神经网络模型可以这样构建：

1.  **线性组合**：首先，输入变量 $x_1, x_2, x_3$ 通过一个带参数 $a, b_1, b_2, b_3$ 的线性函数进行组合，得到中间结果 $z_1^{[1]}$。
    $z_1^{[1]} = a + b_1 x_1 + b_2 x_2 + b_3 x_3$
2.  **激活函数**：然后，将 $z_1^{[1]}$ 通过一个激活函数（例如 ReLU 函数）得到 $c_1^{[1]}$。
    $c_1^{[1]} = \text{ReLU}(z_1^{[1]})$
3.  **输出**：最后，$c_1^{[1]}$ 可能再经过其他处理（例如通过另一个函数 $f$）得到最终的预测值 $\hat{y}$。

---

#### 示例 5.3.1 (续) 神经网络模型

现在让我们构建一个更真实和复杂的神经网络。假设输入为 $x_1, x_2, x_3$。

网络结构可能如下：

*   **隐藏层节点 (例如，两个节点 $a_1, a_2$)**:
    每个节点接收所有输入，并通过各自的权重和偏置进行线性组合，然后通过激活函数（此处未明确指出，但通常会有）。

    $\hat{a}_1 = b_1^{(1)} + w_{11}^{(1)}x_1 + w_{12}^{(1)}x_2 + w_{13}^{(1)}x_3$

    $\hat{a}_2 = b_2^{(1)} + w_{21}^{(1)}x_1 + w_{22}^{(1)}x_2 + w_{23}^{(1)}x_3$

    其中，$b_1^{(1)}, b_2^{(1)}$ 是偏置项，$w_{ij}^{(1)}$ 是连接输入 $x_j$ 到隐藏层节点 $i$ 的权重。上标 $(1)$ 表示第一层。

*   **输出层 ($\hat{y}$)**:
    隐藏层的输出 $a_1, a_2$（或者它们的激活值）会作为下一层（可能是输出层）的输入，经过进一步的变换（例如加权求和并通过激活函数）得到最终的预测值 $\hat{y}$。

    $\hat{y} = \text{g}(a_1, a_2)$ (其中 g 代表输出层的计算)

这种结构允许模型学习输入特征之间更复杂的非线性关系。

---

### 示例 5.3.2 决策树模型

让我们回顾一下鸢尾花（Iris）数据集，其中的花被分为三个类别。如果我们只关注萼片宽度（sepal width）和萼片长度（sepal length），我们可以绘制出一些花的分布情况。

决策树模型通过使用水平线和垂直线来划分特征空间（$x$-空间）。
我们可以持续进行这种划分，直到得到所需数量的子空间。每个子空间通常对应一个预测类别或值。

---

!!! question "课堂练习 5.3.1：模型总结与实现"
    1.  总结前面神经网络和决策树示例中的模型结构和参数。
    2.  你能用 Python 代码实现这两个函数（指模型预测功能）吗？
    3.  你能通过求导来帮助找到参数的估计值吗？（提示：这对于简单模型是可行的，但对于复杂模型通常依赖优化算法。）

## 5.4 Scikit-learn 模块

当模型结构相对简单时，我们可以自己编写函数来表示模型并手动进行数学推导以找到参数的导数。然而，当模型变得更加复杂时，我们很难自行定义函数并进行求导。

例如，一个典型的神经网络模型可能包含数千个神经元（cells）和多个层。下图展示了这个概念。

!!! info "更复杂的神经网络模型示意图"
    下图修改自：[https://doc.comsol.com/6.2/doc/com.comsol.help.comsol/comsol_ref_definitions.19.050.html](https://doc.comsol.com/6.2/doc/com.comsol.help.comsol/comsol_ref_definitions.19.050.html)
    *(注：此处原讲义中提及图片，实际使用时可插入相应图片)*

在这种情况下，我们会求助于 `scikit-learn` 模块。

!!! warning "关于安装 scikit-learn"
    请注意，安装时包名是 `scikit-learn`，而不是 `sklearn`。
    推荐使用 conda 进行安装：
    ```bash
    conda install scikit-learn
    ```

`scikit-learn` 中的机器学习方法使用起来非常相似。让我们编写第一个决策树模型来对鸢尾花进行分类。

```python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn import datasets

# 加载鸢尾花数据集
iris = datasets.load_iris()

# 初始化决策树分类器
clf = DecisionTreeClassifier()

# 训练模型 (使用除最后一个样本外的所有数据进行训练)
# 注意：实际应用中通常会划分训练集和测试集，此处仅为演示
clf = clf.fit(iris.data[:-1], iris.target[:-1])

# 对训练数据进行预测 (同样，除最后一个样本外)
res = clf.predict(iris.data[:-1])

# 查看预测结果 (此处未打印，但 res 变量中存储了预测值)
# print(res)
# print(iris.target[:-1]) # 可以与真实标签比较
```

---

让我们尝试在 `scikit-learn` 中使用神经网络。这里我们使用 `MLPRegressor`（多层感知机回归器）。

```python
from sklearn.neural_network import MLPRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归问题的模拟数据
X, y = make_regression(n_samples=200, n_features=20, random_state=1)

# 将数据划分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

# 初始化MLP回归器
# random_state 用于结果复现, max_iter 是最大迭代次数, tol 是优化的容忍度
regr = MLPRegressor(random_state=1, max_iter=2000, tol=0.1)

# 训练模型
regr.fit(X_train, y_train)

# 对测试集中的前两个样本进行预测
print(regr.predict(X_test[:2]))

#评估模型在测试集上的 R^2 分数
print(regr.score(X_test, y_test))
```

---

当然，`scikit-learn` 也提供了简单的线性模型：

```python
from sklearn import linear_model

# 初始化线性回归模型
reg = linear_model.LinearRegression()

# 训练模型
# 示例数据: [[0,0],[1,1],[2,2]] 为特征, [0,1,2] 为目标值
reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])

# 查看模型系数
print(reg.coef_)
```

---

`scikit-learn` 还提供了许多其他的机器学习模型。如果您需要更多参考资料：

*   **《Python 机器学习实践指南》（Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow）**: 这本书是一个很好的起点。
*   **3Blue1Brown 关于神经网络的视频系列**: 这个视频系列非常侧重于神经网络的直观理解。
*   **深度学习专业书籍（如《深度学习》by Ian Goodfellow, Yoshua Bengio, and Aaron Courville）**: 适用于更高级的神经网络学习。

## 5.5 模型选择与交叉验证

在神经网络建模中，我们可以创建自己的网络结构。例如，我们已经看到了只有一个层且该层中只有一个单元的最简单网络，也看到了具有三个层且每层有多个单元的更复杂网络。

但问题是：这两种都是神经网络模型，哪一个更好呢？

为了回答这个问题，我们需要选择一个特定的模型。这被称为**模型选择问题**。

---

!!! note "交叉验证 (Cross Validation)"
    交叉验证是一种帮助我们选择最佳模型的常用技术。其核心思想是将数据集多次划分为训练集和验证集，在不同的数据子集上评估模型性能，从而得到更稳健的模型评估结果和选择依据。
    
    图片来源与更多信息：[https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html)
    *(注：此处原讲义中提及图片，实际使用时可插入相应图片或参考链接中的图示)*

---

!!! question "课堂练习 5.5.1：使用交叉验证选择线性模型"
    我们来考虑一个简单的线性模型，其中有10个解释变量。数据存储在 `sparsedata.csv` 文件中。这个数据已经包含了目标变量，所以如果我们只对这70个观测值感兴趣，我们不需要任何模型。然而，之后我们又收集了另外30个观测值，但没有目标变量，这些新的解释变量数据存储在 `X_test.csv` 中。换句话说，我们希望训练一个模型来帮助我们预测这些新数据的目标变量。
    
    你可以使用 `scikit-learn` 训练一个线性模型。
    
    通常情况下，并非所有解释变量都能同时有效地预测目标变量，所以我们将只考虑以下几种模型：
    
    1.  $y = a + b_1x_1 + b_2x_2 + b_3x_3 + b_4x_4 + b_5x_5$
    2.  $y = a + b_1x_1 + b_3x_3 + b_5x_5 + b_7x_7 + b_9x_9$
    3.  $y = a + b_2x_2 + b_4x_4 + b_6x_6 + b_8x_8 + b_{10}x_{10}$
    4.  $y = a + b_1x_1 + b_4x_4 + b_8x_8$
    5.  $y = a + b_2x_2 + b_6x_6 + b_9x_9$
        
    请使用交叉验证从上述模型中选择一个最佳模型。
    
    ---
    
    对于这个数据集，我们最终收集了测试集对应的目标变量，并将其存储在 `target_test.csv` 文件中。请使用你选择的模型对这30个观测值进行预测，并评估你的预测效果。
    
    *(注：为完成此练习，你需要 `sparsedata.csv`, `X_test.csv` 和 `target_test.csv` 文件，并编写 Python 代码实现模型训练、交叉验证和预测评估。)*

## 5.6 Kaggle 实践视角

让我们一起了解 Optiver Realized Volatility Prediction 竞赛...
*(讲义文本在此处中断)*
（前文续）...并将其存储在 `X_testcsv` 文件中。换句话说，我们希望训练一个模型来帮助我们预测这些数据的目标变量。下面将介绍如何使用 scikit-learn 训练一个线性模型。

# 5.5 模型选择与交叉验证

!!! question "课堂练习 5.5.1 (续)"
    通常情况下，解释变量并非都能同时有效预测目标变量。因此，我们将仅考虑以下模型：

    𝑦 = 𝑎 + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ + 𝑏₃𝑥₃ + 𝑏₄𝑥₄ + 𝑏₅𝑥₅
    𝑦 = 𝑎 + 𝑏₁𝑥₁ + 𝑏₃𝑥₃ + 𝑏₅𝑥₅ + 𝑏₇𝑥₇ + 𝑏₉𝑥₉
    𝑦 = 𝑎 + 𝑏₂𝑥₂ + 𝑏₄𝑥₄ + 𝑏₆𝑥₆ + 𝑏₈𝑥₈ + 𝑏₁₀𝑥₁₀
    𝑦 = 𝑎 + 𝑏₁𝑥₁ + 𝑏₄𝑥₄ + 𝑏₈𝑥₈
    𝑦 = 𝑎 + 𝑏₂𝑥₂ + 𝑏₆𝑥₆ + 𝑏₉𝑥₉

    请使用交叉验证从上述模型中选择一个最佳模型。
  
针对此数据集，我们最终收集了目标变量，并将其存储在 `target_test.csv` 文件中。请使用您选择的模型对这30个观测值进行预测，并评估预测效果的好坏。

# 5.6 Kaggle 平台实践概览

让我们一起浏览 Optiver Realized Volatility Prediction 任务，来了解 Kaggle 平台的一些基本信息。Kaggle 竞赛页面通常包含以下几个主要选项卡：

## Overview (概述)
在 `Overview` (概述) 选项卡下，我们可以了解到竞赛的背景信息，包括：
*   `Description` (项目描述)
*   `Evaluation` (评估标准)
*   `Timeline` (提交时间表，对于参与进行中的竞赛尤为重要)
*   等等。

## Data (数据)
在 `Data` (数据) 选项卡下，Kaggle 提供了我们训练机器学习模型所需的数据。

!!! note "数据格式提示"
    通常，我们会看到数据集以 `.csv` 以外的其他格式存储。在这种情况下，我们需要学习如何将这些数据导入 Python，并转换为我们熟悉的格式。

继续向下滚动页面，可以看到具体的数据文件列表。

## Code (代码/Notebooks)
在 `Code` (代码/Notebooks) 选项卡下，我们可以看到其他参赛者分享的解决方案和代码。向他人学习 Python 和机器学习技巧是有益的。

!!! warning "学术诚信"
    如果您在自己的项目或解决方案中使用了他人的代码，**务必明确注明来源**。这是学术诚信的基本要求。

让我们看看其他人在这里都做了些什么。

---
*旁边可能有一张图片，例如一个机器人说：“Feed me DATA!”*
*图片来源参考：https://www.jamiesale-cartoonist.com/free-cartoon-robot-vector/*
